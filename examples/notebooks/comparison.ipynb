{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15521d2e-bc0d-4ca7-82d8-6da62bf8893e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e44f182c-4367-4def-8179-e15da8d47b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCompare outputs between original dscim and refactored dscim-new\\n\\nThis script compares the outputs from:\\n  - Original: dscim-testing/run_integration_result.py outputs\\n  - New: reproduce_integration_result.py outputs\\n\\nThe script is structured as sequential code blocks that can be copied into\\nJupyter notebook cells and run step-by-step.\\n\\nKey Comparisons:\\n1. Reduced Damages: Compare shape, dimensions, and values\\n2. Damage Functions: Compare coefficients, marginal damages, and fit statistics\\n3. SCC Results: Compare SCC values across all recipe-discount combinations\\n\\nUsage:\\n  - Set the paths to original and new output directories\\n  - Run each cell sequentially\\n  - Inspect comparison results and visualizations\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Compare outputs between original dscim and refactored dscim-new\n",
    "\n",
    "This script compares the outputs from:\n",
    "  - Original: dscim-testing/run_integration_result.py outputs\n",
    "  - New: reproduce_integration_result.py outputs\n",
    "\n",
    "The script is structured as sequential code blocks that can be copied into\n",
    "Jupyter notebook cells and run step-by-step.\n",
    "\n",
    "Key Comparisons:\n",
    "1. Reduced Damages: Compare shape, dimensions, and values\n",
    "2. Damage Functions: Compare coefficients, marginal damages, and fit statistics\n",
    "3. SCC Results: Compare SCC values across all recipe-discount combinations\n",
    "\n",
    "Usage:\n",
    "  - Set the paths to original and new output directories\n",
    "  - Run each cell sequentially\n",
    "  - Inspect comparison results and visualizations\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8f4caa7f-512e-4d13-9ce7-643eacddfa79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/sebastiancadavidsanchez/Documents/Github/cil/dscim-new\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List, Tuple, Any\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Try to detect if running in Jupyter or as script\n",
    "try:\n",
    "    project_root = Path(__file__).resolve().parent.parent\n",
    "except NameError:\n",
    "    project_root = Path.cwd().resolve().parent.parent\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0aaedf0a-7cd2-49f7-879a-50a717f36da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPARISON SETUP\n",
      "================================================================================\n",
      "\n",
      "Original outputs: /Users/sebastiancadavidsanchez/Documents/Github/cil/dscim-new/dscim-testing/dummy_data\n",
      "New outputs: /Users/sebastiancadavidsanchez/Documents/Github/cil/dscim-new/examples/notebooks/workflow_output\n",
      "Comparison results: /Users/sebastiancadavidsanchez/Documents/Github/cil/dscim-new/notebooks/comparison_results\n",
      "\n",
      "Comparison parameters:\n",
      "  Sector: not_coastal (original: dummy_not_coastl_sector)\n",
      "  Pulse year: 2020\n",
      "  Recipes: ['adding_up', 'risk_aversion', 'equity']\n",
      "  Reductions: ['cc', 'no_cc']\n",
      "  Discount methods: ['constant', 'naive_ramsey', 'euler_ramsey', 'naive_gwr', 'euler_gwr']\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 1: Configuration - Set Paths\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPARISON SETUP\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Path to original dscim-testing outputs\n",
    "ORIGINAL_BASE = project_root / \"dscim-testing\" / \"dummy_data\"\n",
    "\n",
    "# Path to new dscim-new outputs\n",
    "NEW_BASE = project_root / \"examples\" / \"notebooks\" / \"workflow_output\"\n",
    "\n",
    "# Output directory for comparison results\n",
    "COMPARISON_OUTPUT = project_root / \"notebooks\"/ \"comparison_results\"\n",
    "COMPARISON_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\\nOriginal outputs: {ORIGINAL_BASE}\")\n",
    "print(f\"New outputs: {NEW_BASE}\")\n",
    "print(f\"Comparison results: {COMPARISON_OUTPUT}\")\n",
    "\n",
    "# Verify paths exist\n",
    "if not ORIGINAL_BASE.exists():\n",
    "    print(f\"WARNING: Original path does not exist: {ORIGINAL_BASE}\")\n",
    "if not NEW_BASE.exists():\n",
    "    print(f\"WARNING: New path does not exist: {NEW_BASE}\")\n",
    "\n",
    "# Configure comparison parameters\n",
    "SECTOR = \"not_coastal\"  # Sector to compare\n",
    "ORIGINAL_SECTOR = \"dummy_not_coastl_sector\"  # Original sector name\n",
    "PULSE_YEAR = 2020\n",
    "RECIPES = [\"adding_up\", \"risk_aversion\", \"equity\"]\n",
    "REDUCTIONS = [\"cc\", \"no_cc\"]\n",
    "DISCOUNT_METHODS = [\"constant\", \"naive_ramsey\", \"euler_ramsey\", \"naive_gwr\", \"euler_gwr\"]\n",
    "\n",
    "print(f\"\\nComparison parameters:\")\n",
    "print(f\"  Sector: {SECTOR} (original: {ORIGINAL_SECTOR})\")\n",
    "print(f\"  Pulse year: {PULSE_YEAR}\")\n",
    "print(f\"  Recipes: {RECIPES}\")\n",
    "print(f\"  Reductions: {REDUCTIONS}\")\n",
    "print(f\"  Discount methods: {DISCOUNT_METHODS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4681debb-6ba4-440b-85d6-b1efae61dbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Helper functions loaded\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 2: Helper Functions for Comparison\n",
    "# =============================================================================\n",
    "\n",
    "def compare_arrays(\n",
    "    original: xr.DataArray,\n",
    "    new: xr.DataArray,\n",
    "    name: str,\n",
    "    rtol: float = 1e-5,\n",
    "    atol: float = 1e-8,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Compare two xarray DataArrays.\n",
    "\n",
    "    Returns dictionary with comparison results:\n",
    "    - shapes_match: bool\n",
    "    - dims_match: bool\n",
    "    - values_close: bool\n",
    "    - max_abs_diff: float\n",
    "    - max_rel_diff: float\n",
    "    - correlation: float\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        \"name\": name,\n",
    "        \"original_shape\": original.shape if hasattr(original, \"shape\") else None,\n",
    "        \"new_shape\": new.shape if hasattr(new, \"shape\") else None,\n",
    "        \"shapes_match\": False,\n",
    "        \"dims_match\": False,\n",
    "        \"values_close\": False,\n",
    "        \"max_abs_diff\": None,\n",
    "        \"max_rel_diff\": None,\n",
    "        \"correlation\": None,\n",
    "    }\n",
    "\n",
    "    # Check shapes\n",
    "    if hasattr(original, \"shape\") and hasattr(new, \"shape\"):\n",
    "        results[\"shapes_match\"] = original.shape == new.shape\n",
    "\n",
    "    # Check dimensions\n",
    "    if hasattr(original, \"dims\") and hasattr(new, \"dims\"):\n",
    "        results[\"dims_match\"] = set(original.dims) == set(new.dims)\n",
    "        results[\"original_dims\"] = original.dims\n",
    "        results[\"new_dims\"] = new.dims\n",
    "\n",
    "    # Compare values if shapes match\n",
    "    if results[\"shapes_match\"]:\n",
    "        try:\n",
    "            # Align coordinates if needed\n",
    "            orig_aligned, new_aligned = xr.align(original, new, join=\"inner\")\n",
    "\n",
    "            # Convert to numpy for comparison\n",
    "            orig_vals = orig_aligned.values\n",
    "            new_vals = new_aligned.values\n",
    "\n",
    "            # Remove NaNs for comparison\n",
    "            mask = ~(np.isnan(orig_vals) | np.isnan(new_vals))\n",
    "            orig_clean = orig_vals[mask]\n",
    "            new_clean = new_vals[mask]\n",
    "\n",
    "            if len(orig_clean) > 0:\n",
    "                # Check if values are close\n",
    "                results[\"values_close\"] = np.allclose(orig_clean, new_clean, rtol=rtol, atol=atol)\n",
    "\n",
    "                # Calculate differences\n",
    "                abs_diff = np.abs(orig_clean - new_clean)\n",
    "                results[\"max_abs_diff\"] = float(np.max(abs_diff))\n",
    "                results[\"mean_abs_diff\"] = float(np.mean(abs_diff))\n",
    "\n",
    "                # Relative difference (avoid division by zero)\n",
    "                with np.errstate(divide='ignore', invalid='ignore'):\n",
    "                    rel_diff = abs_diff / np.abs(orig_clean)\n",
    "                    rel_diff = rel_diff[np.isfinite(rel_diff)]\n",
    "                    if len(rel_diff) > 0:\n",
    "                        results[\"max_rel_diff\"] = float(np.max(rel_diff))\n",
    "                        results[\"mean_rel_diff\"] = float(np.mean(rel_diff))\n",
    "\n",
    "                # Correlation\n",
    "                if len(orig_clean) > 1:\n",
    "                    results[\"correlation\"] = float(np.corrcoef(orig_clean, new_clean)[0, 1])\n",
    "\n",
    "        except Exception as e:\n",
    "            results[\"error\"] = str(e)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def print_comparison_result(result: Dict[str, Any], verbose: bool = True):\n",
    "    \"\"\"Print comparison result in a readable format.\"\"\"\n",
    "    print(f\"\\n  {result['name']}:\")\n",
    "    print(f\"    Shapes: {result['original_shape']} vs {result['new_shape']} - {'✓' if result['shapes_match'] else '✗'}\")\n",
    "\n",
    "    if verbose and \"original_dims\" in result:\n",
    "        print(f\"    Dims: {result['original_dims']} vs {result['new_dims']} - {'✓' if result['dims_match'] else '✗'}\")\n",
    "\n",
    "    if result[\"values_close\"] is not None:\n",
    "        print(f\"    Values close: {'✓' if result['values_close'] else '✗'}\")\n",
    "\n",
    "        if result[\"max_abs_diff\"] is not None:\n",
    "            print(f\"    Max absolute diff: {result['max_abs_diff']:.2e}\")\n",
    "        if result[\"max_rel_diff\"] is not None:\n",
    "            print(f\"    Max relative diff: {result['max_rel_diff']:.2e}\")\n",
    "        if result[\"correlation\"] is not None:\n",
    "            print(f\"    Correlation: {result['correlation']:.6f}\")\n",
    "\n",
    "    if \"error\" in result:\n",
    "        print(f\"    Error: {result['error']}\")\n",
    "\n",
    "\n",
    "def load_zarr_safe(path: Path) -> xr.Dataset:\n",
    "    \"\"\"Load zarr file, handling both formats.\"\"\"\n",
    "    try:\n",
    "        return xr.open_zarr(path)\n",
    "    except Exception as e:\n",
    "        print(f\"    Error loading {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "print(\"\\nHelper functions loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a794169c-f563-4e0a-bbbb-1c5cc61b2e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 1: COMPARE REDUCED DAMAGES\n",
      "================================================================================\n",
      "\n",
      "Comparing: adding_up x cc\n",
      "  Original: dummy_not_coastl_sector_adding_up_cc.zarr\n",
      "  New: not_coastal_adding_up_cc.zarr\n",
      "  WARNING: Original file not found\n",
      "\n",
      "Comparing: adding_up x no_cc\n",
      "  Original: dummy_not_coastl_sector_adding_up_no_cc.zarr\n",
      "  New: not_coastal_adding_up_no_cc.zarr\n",
      "  WARNING: Original file not found\n",
      "\n",
      "Comparing: risk_aversion x cc\n",
      "  Original: dummy_not_coastl_sector_risk_aversion_cc.zarr\n",
      "  New: not_coastal_risk_aversion_cc.zarr\n",
      "  WARNING: Original file not found\n",
      "\n",
      "Comparing: risk_aversion x no_cc\n",
      "  Original: dummy_not_coastl_sector_risk_aversion_no_cc.zarr\n",
      "  New: not_coastal_risk_aversion_no_cc.zarr\n",
      "  WARNING: Original file not found\n",
      "\n",
      "Comparing: equity x cc\n",
      "  Original: dummy_not_coastl_sector_equity_cc.zarr\n",
      "  New: not_coastal_equity_cc.zarr\n",
      "  WARNING: Original file not found\n",
      "\n",
      "Comparing: equity x no_cc\n",
      "  Original: dummy_not_coastl_sector_equity_no_cc.zarr\n",
      "  New: not_coastal_equity_no_cc.zarr\n",
      "  WARNING: Original file not found\n",
      "\n",
      "Reduced damages comparison complete: 0 comparisons\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 3: Compare Reduced Damages\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 1: COMPARE REDUCED DAMAGES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "reduced_damages_comparisons = {}\n",
    "\n",
    "for recipe in RECIPES:\n",
    "    for reduction in REDUCTIONS:\n",
    "        print(f\"\\nComparing: {recipe} x {reduction}\")\n",
    "\n",
    "        # Build paths for original outputs\n",
    "        # Original naming: {sector}_{recipe}_{reduction}.zarr\n",
    "        original_filename = f\"{ORIGINAL_SECTOR}_{recipe}_{reduction}.zarr\"\n",
    "        original_path = ORIGINAL_BASE / \"reduced_damages\" / original_filename\n",
    "\n",
    "        # Build paths for new outputs\n",
    "        # New naming: {sector}_{recipe}_{reduction}.zarr\n",
    "        new_filename = f\"{SECTOR}_{recipe}_{reduction}.zarr\"\n",
    "        new_path = NEW_BASE / \"reduced_damages\" / new_filename\n",
    "\n",
    "        print(f\"  Original: {original_path.name}\")\n",
    "        print(f\"  New: {new_path.name}\")\n",
    "\n",
    "        # Check if files exist\n",
    "        if not original_path.exists():\n",
    "            print(f\"  WARNING: Original file not found\")\n",
    "            continue\n",
    "        if not new_path.exists():\n",
    "            print(f\"  WARNING: New file not found\")\n",
    "            continue\n",
    "\n",
    "        # Load data\n",
    "        original_data = load_zarr_safe(original_path)\n",
    "        new_data = load_zarr_safe(new_path)\n",
    "\n",
    "        if original_data is None or new_data is None:\n",
    "            continue\n",
    "\n",
    "        # Compare datasets\n",
    "        print(f\"  Original variables: {list(original_data.data_vars)}\")\n",
    "        print(f\"  New variables: {list(new_data.data_vars)}\")\n",
    "\n",
    "        # Compare each variable\n",
    "        common_vars = set(original_data.data_vars) & set(new_data.data_vars)\n",
    "\n",
    "        if len(common_vars) == 0:\n",
    "            print(f\"  WARNING: No common variables found\")\n",
    "            # Try comparing as single array if datasets have single variable\n",
    "            if len(original_data.data_vars) == 1 and len(new_data.data_vars) == 1:\n",
    "                orig_var = list(original_data.data_vars)[0]\n",
    "                new_var = list(new_data.data_vars)[0]\n",
    "                print(f\"  Comparing {orig_var} vs {new_var}\")\n",
    "\n",
    "                result = compare_arrays(\n",
    "                    original_data[orig_var],\n",
    "                    new_data[new_var],\n",
    "                    f\"{recipe}_{reduction}\"\n",
    "                )\n",
    "                print_comparison_result(result)\n",
    "                reduced_damages_comparisons[(recipe, reduction)] = result\n",
    "        else:\n",
    "            for var in common_vars:\n",
    "                result = compare_arrays(\n",
    "                    original_data[var],\n",
    "                    new_data[var],\n",
    "                    f\"{recipe}_{reduction}_{var}\"\n",
    "                )\n",
    "                print_comparison_result(result, verbose=False)\n",
    "                reduced_damages_comparisons[(recipe, reduction, var)] = result\n",
    "\n",
    "print(f\"\\nReduced damages comparison complete: {len(reduced_damages_comparisons)} comparisons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3eeb5134-f02d-4d6c-b60c-401498550534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/sebastiancadavidsanchez/Documents/Github/cil/dscim-new/examples/notebooks/workflow_output')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEW_BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2b1c07c2-e834-40b0-9a4f-e599a978d07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 2: COMPARE DAMAGE FUNCTION COEFFICIENTS\n",
      "================================================================================\n",
      "\n",
      "Comparing damage functions for: adding_up\n",
      "  Original dir: /Users/sebastiancadavidsanchez/Documents/Github/cil/dscim-new/dscim-testing/dummy_data/results/AR6_ssp/dummy_not_coastl_sector/2020/unmasked\n",
      "  New dir: /Users/sebastiancadavidsanchez/Documents/Github/cil/dscim-new/examples/notebooks/workflow_output/damage_functions/not_coastal/2020\n",
      "  New coefficients loaded: FrozenMappingWarningOnValuesAccess({'coefficient': 2})\n",
      "  Found 5 original coefficient files\n",
      "  Comparing with: adding_up_constant_eta2.0_rho0.0001_damage_function_coefficients.nc4\n",
      "\n",
      "  adding_up_coefficients:\n",
      "    Shapes: (2, 3, 2, 81) vs (2,) - ✗\n",
      "    Dims: ('variable', 'ssp', 'model', 'year') vs ('coefficient',) - ✗\n",
      "    Values close: ✗\n",
      "\n",
      "Comparing damage functions for: risk_aversion\n",
      "  Original dir: /Users/sebastiancadavidsanchez/Documents/Github/cil/dscim-new/dscim-testing/dummy_data/results/AR6_ssp/dummy_not_coastl_sector/2020/unmasked\n",
      "  New dir: /Users/sebastiancadavidsanchez/Documents/Github/cil/dscim-new/examples/notebooks/workflow_output/damage_functions/not_coastal/2020\n",
      "  New coefficients loaded: FrozenMappingWarningOnValuesAccess({'coefficient': 2})\n",
      "  Found 5 original coefficient files\n",
      "  Comparing with: risk_aversion_euler_gwr_eta2.0_rho0.0001_damage_function_coefficients.nc4\n",
      "\n",
      "  risk_aversion_coefficients:\n",
      "    Shapes: (2, 81) vs (2,) - ✗\n",
      "    Dims: ('variable', 'year') vs ('coefficient',) - ✗\n",
      "    Values close: ✗\n",
      "\n",
      "Comparing damage functions for: equity\n",
      "  Original dir: /Users/sebastiancadavidsanchez/Documents/Github/cil/dscim-new/dscim-testing/dummy_data/results/AR6_ssp/dummy_not_coastl_sector/2020/unmasked\n",
      "  New dir: /Users/sebastiancadavidsanchez/Documents/Github/cil/dscim-new/examples/notebooks/workflow_output/damage_functions/not_coastal/2020\n",
      "  New coefficients loaded: FrozenMappingWarningOnValuesAccess({'coefficient': 2})\n",
      "  Found 5 original coefficient files\n",
      "  Comparing with: equity_euler_gwr_eta2.0_rho0.0001_damage_function_coefficients.nc4\n",
      "\n",
      "  equity_coefficients:\n",
      "    Shapes: (2, 81) vs (2,) - ✗\n",
      "    Dims: ('variable', 'year') vs ('coefficient',) - ✗\n",
      "    Values close: ✗\n",
      "\n",
      "Damage function comparison complete: 3 comparisons\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 4: Compare Damage Function Coefficients\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 2: COMPARE DAMAGE FUNCTION COEFFICIENTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "damage_function_comparisons = {}\n",
    "\n",
    "for recipe in RECIPES:\n",
    "    print(f\"\\nComparing damage functions for: {recipe}\")\n",
    "\n",
    "    # Original path structure: results/AR6_ssp/{sector}/{pulse_year}/unmasked/\n",
    "    # Files named: {recipe}_{discount}_eta{eta}_rho{rho}_damage_function_coefficients.nc4\n",
    "    # Note: Original has one file per recipe-discount combo\n",
    "\n",
    "    # New path structure: damage_functions/{sector}/{pulse_year}/\n",
    "    # Files named: damage_function_coefficients.zarr\n",
    "    # Note: New has one file per recipe (discount applied later in SCC step)\n",
    "\n",
    "    original_ar6_dir = ORIGINAL_BASE / \"results\" / \"AR6_ssp\" / ORIGINAL_SECTOR / str(PULSE_YEAR) / \"unmasked\"\n",
    "    new_dir = NEW_BASE / \"damage_functions\" / SECTOR / str(PULSE_YEAR)\n",
    "\n",
    "    print(f\"  Original dir: {original_ar6_dir}\")\n",
    "    print(f\"  New dir: {new_dir}\")\n",
    "\n",
    "    if not original_ar6_dir.exists():\n",
    "        print(f\"  WARNING: Original directory not found\")\n",
    "        continue\n",
    "    if not new_dir.exists():\n",
    "        print(f\"  WARNING: New directory not found\")\n",
    "        continue\n",
    "\n",
    "    # New coefficients path (one per recipe)\n",
    "    new_coef_path = new_dir / \"damage_function_coefficients.zarr\"\n",
    "\n",
    "    if not new_coef_path.exists():\n",
    "        print(f\"  WARNING: New coefficients not found\")\n",
    "        continue\n",
    "\n",
    "    # Load new coefficients\n",
    "    new_coefs = load_zarr_safe(new_coef_path)\n",
    "    if new_coefs is None:\n",
    "        continue\n",
    "\n",
    "    print(f\"  New coefficients loaded: {new_coefs.dims if hasattr(new_coefs, 'dims') else 'Dataset'}\")\n",
    "\n",
    "    # Find original coefficient files for this recipe\n",
    "    # Pattern: {recipe}_*_damage_function_coefficients.nc4\n",
    "    pattern = f\"{recipe}_*_damage_function_coefficients.nc4\"\n",
    "    original_coef_files = list(original_ar6_dir.glob(pattern))\n",
    "\n",
    "    if not original_coef_files:\n",
    "        print(f\"  WARNING: No original coefficient files found (pattern: {pattern})\")\n",
    "        continue\n",
    "\n",
    "    print(f\"  Found {len(original_coef_files)} original coefficient files\")\n",
    "\n",
    "    # Compare with first file (they should all have same coefficients since\n",
    "    # coefficients are fitted before discount methods are applied)\n",
    "    original_coef_path = original_coef_files[0]\n",
    "    print(f\"  Comparing with: {original_coef_path.name}\")\n",
    "\n",
    "    original_coefs = xr.open_dataset(original_coef_path)\n",
    "\n",
    "    # Extract coefficient values for comparison\n",
    "    orig_data = original_coefs.to_array().squeeze() if isinstance(original_coefs, xr.Dataset) else original_coefs\n",
    "    new_data = new_coefs.to_array().squeeze() if isinstance(new_coefs, xr.Dataset) else new_coefs\n",
    "\n",
    "    result = compare_arrays(\n",
    "        orig_data,\n",
    "        new_data,\n",
    "        f\"{recipe}_coefficients\"\n",
    "    )\n",
    "    print_comparison_result(result)\n",
    "    damage_function_comparisons[recipe] = result\n",
    "\n",
    "print(f\"\\nDamage function comparison complete: {len(damage_function_comparisons)} comparisons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364f24ee-c34f-4fa0-bb00-fdce86419d48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc497ef-3fa9-4c10-80c9-375e8f28e1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls /Users/sebastiancadavidsanchez/Documents/Github/cil/dscim-new/dscim-testing/dummy_data/\n",
    "climate/              reduced_damages/      sectoral/\n",
    "econ/                 results/              ssp_damage_functions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79372b6b-2377-467a-a1f4-2b1cbf0ad09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "im geting the following mensages when coparing coefficients\n",
    "  WARNING: Original directory not found\n",
    "the problem is that the original directorie have like different names, how can I fix that\n",
    "ls /Users/sebastiancadavidsanchez/Documents/Github/cil/dscim-new/dscim-testing/dummy_data/\n",
    "climate/              reduced_damages/      sectoral/\n",
    "econ/                 results/              ssp_damage_functions/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4aacb6-7de9-46ae-8f43-3a9b5549d52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls /Users/sebastiancadavidsanchez/Documents/Github/cil/dscim-new/dscim-testing/dummy_data/results/AR6_ssp/dummy_not_coastl_sector/2020/unmasked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3ec6ff-1508-447c-b2a4-eb0762d4238e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CELL 5: Compare Marginal Damages\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 3: COMPARE MARGINAL DAMAGES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "marginal_damages_comparisons = {}\n",
    "\n",
    "for recipe in RECIPES:\n",
    "    print(f\"\\nComparing marginal damages for: {recipe}\")\n",
    "\n",
    "    # New path\n",
    "    new_dir = NEW_BASE / \"damage_functions\" / SECTOR / str(PULSE_YEAR)\n",
    "    new_marg_path = new_dir / \"marginal_damages.zarr\"\n",
    "\n",
    "    # Original path (in AR6_ssp results)\n",
    "    original_ar6_dir = ORIGINAL_BASE / \"results\" / \"AR6_ssp\" / ORIGINAL_SECTOR / str(PULSE_YEAR) / \"unmasked\"\n",
    "\n",
    "    if not new_marg_path.exists():\n",
    "        print(f\"  WARNING: New marginal damages not found\")\n",
    "        continue\n",
    "\n",
    "    if not original_ar6_dir.exists():\n",
    "        print(f\"  WARNING: Original directory not found\")\n",
    "        continue\n",
    "\n",
    "    # Load new marginal damages\n",
    "    new_marg = load_zarr_safe(new_marg_path)\n",
    "\n",
    "    if new_marg is None:\n",
    "        continue\n",
    "\n",
    "    print(f\"  New marginal damages: {new_marg.dims if hasattr(new_marg, 'dims') else 'loaded'}\")\n",
    "\n",
    "    # Find original marginal damages files\n",
    "    pattern = f\"{recipe}_*_marginal_damages.nc\"\n",
    "    original_marg_files = list(original_ar6_dir.glob(pattern))\n",
    "\n",
    "    if original_marg_files:\n",
    "        print(f\"  Found {len(original_marg_files)} original marginal damage files\")\n",
    "        # Load first one\n",
    "        original_marg = xr.open_dataset(original_marg_files[0])\n",
    "\n",
    "        result = compare_arrays(\n",
    "            original_marg.to_array().squeeze(),\n",
    "            new_marg.to_array().squeeze() if isinstance(new_marg, xr.Dataset) else new_marg,\n",
    "            f\"{recipe}_marginal_damages\"\n",
    "        )\n",
    "        print_comparison_result(result)\n",
    "        marginal_damages_comparisons[recipe] = result\n",
    "    else:\n",
    "        print(f\"  WARNING: No original marginal damages found\")\n",
    "\n",
    "print(f\"\\nMarginal damages comparison complete: {len(marginal_damages_comparisons)} comparisons\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CELL 6: Compare SCC Results - All Combinations\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 4: COMPARE SCC RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "scc_comparisons = {}\n",
    "\n",
    "# Map discount method names (new vs original)\n",
    "discount_name_map = {\n",
    "    \"constant\": \"constant\",\n",
    "    \"naive_ramsey\": \"naive_ramsey\",\n",
    "    \"euler_ramsey\": \"euler_ramsey\",\n",
    "    \"naive_gwr\": \"naive_gwr\",\n",
    "    \"euler_gwr\": \"euler_gwr\",\n",
    "}\n",
    "\n",
    "for recipe in RECIPES:\n",
    "    for discount_method in DISCOUNT_METHODS:\n",
    "        print(f\"\\nComparing SCC: {recipe} x {discount_method}\")\n",
    "\n",
    "        # Original path: AR6_ssp/{sector}/{pulse_year}/unmasked/\n",
    "        # File: {recipe}_{discount}_eta{eta}_rho{rho}_scc.nc\n",
    "        original_ar6_dir = ORIGINAL_BASE / \"results\" / \"AR6_ssp\" / ORIGINAL_SECTOR / str(PULSE_YEAR) / \"unmasked\"\n",
    "\n",
    "        # New path: scc_results/{sector}/{pulse_year}/\n",
    "        # File: {recipe}_{discount}_scc.zarr\n",
    "        new_scc_dir = NEW_BASE / \"scc_results\" / SECTOR / str(PULSE_YEAR)\n",
    "\n",
    "        # Build filenames\n",
    "        # Original uses eta and rho in filename\n",
    "        original_pattern = f\"{recipe}_{discount_method}_eta*_rho*_scc.nc\"\n",
    "        new_filename = f\"{recipe}_{discount_method}_scc.zarr\"\n",
    "\n",
    "        # Find original file\n",
    "        if original_ar6_dir.exists():\n",
    "            original_scc_files = list(original_ar6_dir.glob(original_pattern))\n",
    "\n",
    "            if not original_scc_files:\n",
    "                print(f\"  WARNING: Original SCC file not found (pattern: {original_pattern})\")\n",
    "                continue\n",
    "\n",
    "            original_scc_path = original_scc_files[0]\n",
    "            print(f\"  Original: {original_scc_path.name}\")\n",
    "        else:\n",
    "            print(f\"  WARNING: Original directory not found\")\n",
    "            continue\n",
    "\n",
    "        # Check new file\n",
    "        new_scc_path = new_scc_dir / new_filename\n",
    "\n",
    "        if not new_scc_path.exists():\n",
    "            print(f\"  WARNING: New SCC file not found: {new_filename}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"  New: {new_scc_path.name}\")\n",
    "\n",
    "        # Load data\n",
    "        try:\n",
    "            original_scc = xr.open_dataset(original_scc_path)\n",
    "            new_scc = load_zarr_safe(new_scc_path)\n",
    "\n",
    "            if new_scc is None:\n",
    "                continue\n",
    "\n",
    "            # Compare SCC values\n",
    "            # Extract the main SCC variable\n",
    "            orig_scc_var = \"scc\" if \"scc\" in original_scc else list(original_scc.data_vars)[0]\n",
    "            new_scc_var = \"scc\" if \"scc\" in new_scc else list(new_scc.data_vars)[0]\n",
    "\n",
    "            result = compare_arrays(\n",
    "                original_scc[orig_scc_var],\n",
    "                new_scc[new_scc_var],\n",
    "                f\"{recipe}_{discount_method}_scc\"\n",
    "            )\n",
    "            print_comparison_result(result)\n",
    "            scc_comparisons[(recipe, discount_method)] = result\n",
    "\n",
    "            # Calculate and print mean SCC values\n",
    "            orig_mean = float(original_scc[orig_scc_var].mean())\n",
    "            new_mean = float(new_scc[new_scc_var].mean())\n",
    "            print(f\"    Mean SCC: {orig_mean:.2f} (original) vs {new_mean:.2f} (new)\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR: {e}\")\n",
    "\n",
    "print(f\"\\nSCC comparison complete: {len(scc_comparisons)} comparisons\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CELL 7: Summary Statistics\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPARISON SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def summarize_comparisons(comparisons: Dict, title: str):\n",
    "    \"\"\"Print summary of comparison results.\"\"\"\n",
    "    print(f\"\\n{title}:\")\n",
    "    print(f\"  Total comparisons: {len(comparisons)}\")\n",
    "\n",
    "    if len(comparisons) == 0:\n",
    "        return\n",
    "\n",
    "    shapes_match = sum(1 for r in comparisons.values() if r.get(\"shapes_match\", False))\n",
    "    values_close = sum(1 for r in comparisons.values() if r.get(\"values_close\", False))\n",
    "\n",
    "    print(f\"  Shapes match: {shapes_match}/{len(comparisons)} ({100*shapes_match/len(comparisons):.1f}%)\")\n",
    "    print(f\"  Values close: {values_close}/{len(comparisons)} ({100*values_close/len(comparisons):.1f}%)\")\n",
    "\n",
    "    # Average differences\n",
    "    max_abs_diffs = [r[\"max_abs_diff\"] for r in comparisons.values() if r.get(\"max_abs_diff\") is not None]\n",
    "    if max_abs_diffs:\n",
    "        print(f\"  Average max absolute diff: {np.mean(max_abs_diffs):.2e}\")\n",
    "\n",
    "    max_rel_diffs = [r[\"max_rel_diff\"] for r in comparisons.values() if r.get(\"max_rel_diff\") is not None]\n",
    "    if max_rel_diffs:\n",
    "        print(f\"  Average max relative diff: {np.mean(max_rel_diffs):.2e}\")\n",
    "\n",
    "    correlations = [r[\"correlation\"] for r in comparisons.values() if r.get(\"correlation\") is not None]\n",
    "    if correlations:\n",
    "        print(f\"  Average correlation: {np.mean(correlations):.6f}\")\n",
    "\n",
    "summarize_comparisons(reduced_damages_comparisons, \"Reduced Damages\")\n",
    "summarize_comparisons(damage_function_comparisons, \"Damage Function Coefficients\")\n",
    "summarize_comparisons(marginal_damages_comparisons, \"Marginal Damages\")\n",
    "summarize_comparisons(scc_comparisons, \"SCC Results\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CELL 8: Save Comparison Report\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAVING COMPARISON REPORT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create detailed report\n",
    "report_lines = []\n",
    "report_lines.append(\"# DSCIM Output Comparison Report\\n\")\n",
    "report_lines.append(f\"Generated: {pd.Timestamp.now()}\\n\\n\")\n",
    "report_lines.append(f\"Original outputs: {ORIGINAL_BASE}\\n\")\n",
    "report_lines.append(f\"New outputs: {NEW_BASE}\\n\\n\")\n",
    "\n",
    "def format_comparison_section(comparisons: Dict, title: str) -> List[str]:\n",
    "    \"\"\"Format comparison results as markdown.\"\"\"\n",
    "    lines = [f\"\\n## {title}\\n\\n\"]\n",
    "\n",
    "    if len(comparisons) == 0:\n",
    "        lines.append(\"No comparisons performed.\\n\\n\")\n",
    "        return lines\n",
    "\n",
    "    # Create summary table\n",
    "    lines.append(\"| Comparison | Shapes Match | Values Close | Max Abs Diff | Correlation |\\n\")\n",
    "    lines.append(\"|------------|--------------|--------------|--------------|-------------|\\n\")\n",
    "\n",
    "    for key, result in comparisons.items():\n",
    "        name = result.get(\"name\", str(key))\n",
    "        shapes = \"✓\" if result.get(\"shapes_match\", False) else \"✗\"\n",
    "        values = \"✓\" if result.get(\"values_close\", False) else \"✗\"\n",
    "        max_diff = f\"{result['max_abs_diff']:.2e}\" if result.get(\"max_abs_diff\") is not None else \"N/A\"\n",
    "        corr = f\"{result['correlation']:.4f}\" if result.get(\"correlation\") is not None else \"N/A\"\n",
    "\n",
    "        lines.append(f\"| {name} | {shapes} | {values} | {max_diff} | {corr} |\\n\")\n",
    "\n",
    "    lines.append(\"\\n\")\n",
    "    return lines\n",
    "\n",
    "report_lines.extend(format_comparison_section(reduced_damages_comparisons, \"Reduced Damages\"))\n",
    "report_lines.extend(format_comparison_section(damage_function_comparisons, \"Damage Function Coefficients\"))\n",
    "report_lines.extend(format_comparison_section(marginal_damages_comparisons, \"Marginal Damages\"))\n",
    "report_lines.extend(format_comparison_section(scc_comparisons, \"SCC Results\"))\n",
    "\n",
    "# Save report\n",
    "report_path = COMPARISON_OUTPUT / \"comparison_report.md\"\n",
    "with open(report_path, \"w\") as f:\n",
    "    f.writelines(report_lines)\n",
    "\n",
    "print(f\"\\nComparison report saved to: {report_path}\")\n",
    "\n",
    "# Also save as CSV for easy analysis\n",
    "all_comparisons = []\n",
    "for comp_dict, comp_type in [\n",
    "    (reduced_damages_comparisons, \"reduced_damages\"),\n",
    "    (damage_function_comparisons, \"damage_function\"),\n",
    "    (marginal_damages_comparisons, \"marginal_damages\"),\n",
    "    (scc_comparisons, \"scc\"),\n",
    "]:\n",
    "    for key, result in comp_dict.items():\n",
    "        row = {\n",
    "            \"type\": comp_type,\n",
    "            \"comparison\": result.get(\"name\", str(key)),\n",
    "            \"shapes_match\": result.get(\"shapes_match\", None),\n",
    "            \"values_close\": result.get(\"values_close\", None),\n",
    "            \"max_abs_diff\": result.get(\"max_abs_diff\", None),\n",
    "            \"mean_abs_diff\": result.get(\"mean_abs_diff\", None),\n",
    "            \"max_rel_diff\": result.get(\"max_rel_diff\", None),\n",
    "            \"correlation\": result.get(\"correlation\", None),\n",
    "        }\n",
    "        all_comparisons.append(row)\n",
    "\n",
    "if all_comparisons:\n",
    "    df = pd.DataFrame(all_comparisons)\n",
    "    csv_path = COMPARISON_OUTPUT / \"comparison_results.csv\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Comparison data saved to: {csv_path}\")\n",
    "\n",
    "print(\"\\nComparison complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dscim-refactoring-dev)",
   "language": "python",
   "name": "dscim-refactoring-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
